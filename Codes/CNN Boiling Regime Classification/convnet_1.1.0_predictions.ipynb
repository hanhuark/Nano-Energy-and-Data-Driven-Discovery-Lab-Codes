{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version History:\n",
    "- v1.0.0: Just using the tutorial code and running.\n",
    "- v1.1.0: Added methods to return class per video in each dataset and make confusion matrix for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras \n",
    "from keras_video import VideoFrameGenerator\n",
    "from keras.layers import Conv2D, BatchNormalization, \\\n",
    "    MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with 2 classes:\n",
    "classes = ['class_00', 'class_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sub directories names as classes\n",
    "test_classes = [i.split(os.path.sep)[5] for i in glob.glob('F:\\\\DS_Datasets\\\\DS1\\\\DS1nmax_split\\\\test\\\\*')]\n",
    "test_classes.sort()\n",
    "\n",
    "train_classes = [i.split(os.path.sep)[5] for i in glob.glob('F:\\\\DS_Datasets\\\\DS1\\\\DS1nmax_split\\\\train\\\\*')]\n",
    "train_classes.sort()\n",
    "\n",
    "ds3_classes = [i.split(os.path.sep)[5] for i in glob.glob('D:\\\\DS_Datasets\\\\Updated_DS_AVI\\\\DS3\\\\DS3Nmax\\\\*')]\n",
    "ds3_classes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global params\n",
    "SIZE = (128, 128)\n",
    "CHANNELS = 3\n",
    "NBFRAME = 16\n",
    "BS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern to get videos and classes\n",
    "#glob_pattern='D:\\\\DS_Datasets\\\\Updated_DS_AVI\\\\DS1\\\\DS1Nmax test\\\\{classname}\\\\*.avi'\n",
    "test_pattern = 'F:\\\\DS_Datasets\\\\DS1\\\\DS1nmax_split\\\\test\\\\{classname}\\\\*.avi'\n",
    "train_pattern = 'F:\\\\DS_Datasets\\\\DS1\\\\DS1nmax_split\\\\train\\\\{classname}\\\\*.avi'\n",
    "ds3_pattern = 'D:\\\\DS_Datasets\\\\Updated_DS_AVI\\\\DS3\\\\DS3Nmax\\\\{classname}\\\\*.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 22 classes for 4133 files for train\n"
     ]
    }
   ],
   "source": [
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=train_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 19 classes for 11191 files for train\n"
     ]
    }
   ],
   "source": [
    "ds3 = VideoFrameGenerator(\n",
    "    classes=ds3_classes, \n",
    "    glob_pattern=ds3_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 22 classes for 1319 files for train\n"
     ]
    }
   ],
   "source": [
    "test = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=test_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    shuffle=False,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_per_video(vdg, classlist):\n",
    "    #vdg = video data generator\n",
    "    class_indices = []\n",
    "    for i in range(vdg.files_count):\n",
    "        class_indices.append([classlist.index(x) for x in classlist if x in vdg._get_classname(vdg.files[i])][0])\n",
    "    return class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convnet(shape=(128, 128, 3)):\n",
    "    momentum = .9\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
    "              padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "   \n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "   \n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    # flatten...\n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_model(shape=(5, 128, 128, 3), nbout=len(classes)):\n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()    # add the convnet with (5, 112, 112, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))    # and finally, we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=20\n",
    "\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"ds1_convnet_50epochs_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  26/1398 [..............................] - ETA: 1:56:07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_07\\14W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  48/1398 [>.............................] - ETA: 1:54:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_03\\6W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  84/1398 [>.............................] - ETA: 1:50:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_13\\26W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 146/1398 [==>...........................] - ETA: 1:44:11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_08\\16W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 294/1398 [=====>........................] - ETA: 1:31:45"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_10\\20W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 439/1398 [========>.....................] - ETA: 1:19:17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_17\\34W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 483/1398 [=========>....................] - ETA: 1:15:36"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_00\\2W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 484/1398 [=========>....................] - ETA: 1:15:31"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_19\\38W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 496/1398 [=========>....................] - ETA: 1:14:28"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_06\\12W_cannon589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 622/1398 [============>.................] - ETA: 1:04:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_15\\30W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 623/1398 [============>.................] - ETA: 1:03:55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_14\\28W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 668/1398 [=============>................] - ETA: 1:00:08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_09\\18W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 687/1398 [=============>................] - ETA: 58:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_12\\24W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 708/1398 [==============>...............] - ETA: 56:48"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_02\\4W_2589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 711/1398 [==============>...............] - ETA: 56:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_11\\22W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 749/1398 [===============>..............] - ETA: 53:25"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_16\\32W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 798/1398 [================>.............] - ETA: 49:22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_05\\10W_cannon589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1398 [=======================>......] - ETA: 22:22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_04\\8W_cannon589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1308/1398 [===========================>..] - ETA: 7:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video D:\\DS_Datasets\\Updated_DS_AVI\\DS3\\DS3Nmax\\class_18\\36W589.avi, 6 total, 6 extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398/1398 [==============================] - 6906s 5s/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_generator(ds3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398\n"
     ]
    }
   ],
   "source": [
    "print(len(ds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11165\n"
     ]
    }
   ],
   "source": [
    "print(len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_report = np.argmax(predict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = class_per_video(ds3, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11165\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11191\n"
     ]
    }
   ],
   "source": [
    "print(len(class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 85  16 135  13   2   1   0   3   1   0  19  14   4  10  85  40   0   3\n",
      "    0  16 142]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [131  19 106   7   2   0   0   0   0   0  14  13   8   9  80  36   0   1\n",
      "    0  18 145]\n",
      " [ 96  15 127  10   1   0   0   1   3   1  19  14   4   7  81  24   0   3\n",
      "    2  22 159]\n",
      " [ 97  14 126  11   2   0   0   2   1   0  12  13   4   6  70  29   0   4\n",
      "    0  17 181]\n",
      " [ 92  17 142  10   1   1   0   0   1   0  22   9   8  11  73  34   0   1\n",
      "    1  21 145]\n",
      " [102  22 133   7   3   1   0   1   2   0  21  17   6   6  67  34   0   2\n",
      "    1  16 148]\n",
      " [101  19 124   9   4   0   0   2   1   0  14  12   4  16  79  32   0   3\n",
      "    1  19 149]\n",
      " [ 99  13 125   7   3   0   0   1   0   0  15  14   4  10  78  45   0   2\n",
      "    1  21 151]\n",
      " [ 90  17 129  12   0   1   0   2   3   1  12  12   7  10  91  30   0   2\n",
      "    1  21 148]\n",
      " [105  10 134   3   3   0   0   0   2   0  19  19   7   9  85  36   0   2\n",
      "    1  25 129]\n",
      " [111  14  97   9   5   0   0   2   0   0  16   9   8  13  85  33   0   2\n",
      "    0  17 168]\n",
      " [ 85  13 122  12   3   0   0   2   3   0  18   7   5  17  86  36   0   0\n",
      "    2  21 157]\n",
      " [101  17 131   5   3   1   0   3   1   0  15  12   8  17  71  23   0   1\n",
      "    1  22 157]\n",
      " [ 87  12 141   8   3   0   0   2   0   0  11  16   7  12  86  22   0   2\n",
      "    0  16 164]\n",
      " [ 74  16 135   9   1   0   0   3   1   1  19  18   5  13  76  34   0   1\n",
      "    0  15 168]\n",
      " [104  11 132   7   3   1   0   1   3   0  13  12   8  12  87  28   0   2\n",
      "    0  21 144]\n",
      " [ 98  10 132  10   1   0   0   3   1   0  17  12   7   4  73  25   0   4\n",
      "    0  19 173]\n",
      " [100  12 145   8   2   0   0   0   3   0  14  13  10   8  71  24   0   4\n",
      "    1  20 154]\n",
      " [ 72  13 141  11   5   0   0   3   0   0  15  11   5  11  87  33   0   3\n",
      "    0  17 136]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "matrix=confusion_matrix(class_indices[:-26], y_pred_report)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_pred = y_pred_report\n",
    "random.shuffle(shuffled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1\n",
      " 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[29 31]\n",
      " [31 29]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "matrix=confusion_matrix(class_indices, shuffled_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss');\n",
    "plt.plot(history.history['val_loss'], label='val_loss');\n",
    "plt.xlabel('epoch');\n",
    "plt.title('Loss and Validation Loss per Epoch')\n",
    "plt.legend();\n",
    "plt.savefig('loss_val_loss_convnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy');\n",
    "plt.plot(history.history['val_acc'], label='val_accuracy');\n",
    "plt.xlabel('epoch');\n",
    "plt.title('Accuracy and Validation Accuracy per Epoch')\n",
    "plt.legend();\n",
    "plt.savefig('acc_val_acc_convnet.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
