{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version History:\n",
    "- v1.0.0: Just using the tutorial code and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras \n",
    "from keras_video import VideoFrameGenerator\n",
    "from keras.layers import Conv2D, BatchNormalization, \\\n",
    "    MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sub directories names as classes\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('videos/*')]\n",
    "classes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global params\n",
    "SIZE = (112, 112)\n",
    "CHANNELS = 3\n",
    "NBFRAME = 5\n",
    "BS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern to get videos and classes\n",
    "glob_pattern='videos/{classname}/*.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning, `split` argument is replaced by `split_val`, please condider to change your source code.The `split` argument will be removed in future releases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dribble, validation count: 47, train count: 98\n",
      "class golf, validation count: 34, train count: 71\n",
      "class kick_ball, validation count: 42, train count: 86\n",
      "Total data: 3 classes for 255 files for train\n"
     ]
    }
   ],
   "source": [
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split=.33, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 3 classes for 123 files for validation\n"
     ]
    }
   ],
   "source": [
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convnet(shape=(112, 112, 3)):\n",
    "    momentum = .9\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
    "              padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "   \n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "   \n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    # flatten...\n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()    # add the convnet with (5, 112, 112, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))    # and finally, we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 147s 5s/step - loss: 1.1220 - acc: 0.3911 - val_loss: 0.9973 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00001: saving model to chkp/weights.01-1.00.hdf5\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 147s 5s/step - loss: 1.0752 - acc: 0.4597 - val_loss: 1.1152 - val_acc: 0.4917\n",
      "\n",
      "Epoch 00002: saving model to chkp/weights.02-1.12.hdf5\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 156s 5s/step - loss: 1.0963 - acc: 0.4274 - val_loss: 1.1279 - val_acc: 0.5083\n",
      "\n",
      "Epoch 00003: saving model to chkp/weights.03-1.13.hdf5\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 161s 5s/step - loss: 0.9995 - acc: 0.5565 - val_loss: 0.8338 - val_acc: 0.6167\n",
      "\n",
      "Epoch 00004: saving model to chkp/weights.04-0.83.hdf5\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 164s 5s/step - loss: 0.9536 - acc: 0.5202 - val_loss: 0.5708 - val_acc: 0.6917\n",
      "\n",
      "Epoch 00005: saving model to chkp/weights.05-0.57.hdf5\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 172s 6s/step - loss: 0.9852 - acc: 0.5766 - val_loss: 1.2922 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00006: saving model to chkp/weights.06-1.29.hdf5\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 177s 6s/step - loss: 0.9363 - acc: 0.5847 - val_loss: 1.4397 - val_acc: 0.4917\n",
      "\n",
      "Epoch 00007: saving model to chkp/weights.07-1.44.hdf5\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 172s 6s/step - loss: 0.9971 - acc: 0.5685 - val_loss: 0.9792 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00008: saving model to chkp/weights.08-0.98.hdf5\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 163s 5s/step - loss: 0.9364 - acc: 0.6089 - val_loss: 0.9379 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00009: saving model to chkp/weights.09-0.94.hdf5\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 168s 5s/step - loss: 0.8551 - acc: 0.6613 - val_loss: 0.8958 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00010: saving model to chkp/weights.10-0.90.hdf5\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 185s 6s/step - loss: 1.0355 - acc: 0.5323 - val_loss: 0.8536 - val_acc: 0.6583\n",
      "\n",
      "Epoch 00011: saving model to chkp/weights.11-0.85.hdf5\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 182s 6s/step - loss: 0.8963 - acc: 0.6008 - val_loss: 0.8283 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00012: saving model to chkp/weights.12-0.83.hdf5\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 171s 6s/step - loss: 0.7728 - acc: 0.7137 - val_loss: 1.4922 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00013: saving model to chkp/weights.13-1.49.hdf5\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 168s 5s/step - loss: 0.7300 - acc: 0.7419 - val_loss: 1.5313 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00014: saving model to chkp/weights.14-1.53.hdf5\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 166s 5s/step - loss: 0.7862 - acc: 0.6653 - val_loss: 1.0945 - val_acc: 0.5167\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00015: saving model to chkp/weights.15-1.09.hdf5\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 157s 5s/step - loss: 0.9602 - acc: 0.6411 - val_loss: 0.5790 - val_acc: 0.6833\n",
      "\n",
      "Epoch 00016: saving model to chkp/weights.16-0.58.hdf5\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 152s 5s/step - loss: 0.7461 - acc: 0.7258 - val_loss: 0.5912 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00017: saving model to chkp/weights.17-0.59.hdf5\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 152s 5s/step - loss: 0.6360 - acc: 0.7379 - val_loss: 0.6136 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00018: saving model to chkp/weights.18-0.61.hdf5\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 152s 5s/step - loss: 0.6648 - acc: 0.7581 - val_loss: 0.6389 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00019: saving model to chkp/weights.19-0.64.hdf5\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 151s 5s/step - loss: 0.6437 - acc: 0.7419 - val_loss: 0.7209 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00020: saving model to chkp/weights.20-0.72.hdf5\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 157s 5s/step - loss: 0.6143 - acc: 0.7661 - val_loss: 0.2966 - val_acc: 0.7833\n",
      "\n",
      "Epoch 00021: saving model to chkp/weights.21-0.30.hdf5\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 171s 6s/step - loss: 0.6223 - acc: 0.7540 - val_loss: 0.4709 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00022: saving model to chkp/weights.22-0.47.hdf5\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 168s 5s/step - loss: 0.5561 - acc: 0.7863 - val_loss: 0.6779 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00023: saving model to chkp/weights.23-0.68.hdf5\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 170s 5s/step - loss: 0.5223 - acc: 0.7823 - val_loss: 0.3812 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00024: saving model to chkp/weights.24-0.38.hdf5\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 164s 5s/step - loss: 0.7143 - acc: 0.7298 - val_loss: 0.5368 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00025: saving model to chkp/weights.25-0.54.hdf5\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 173s 6s/step - loss: 0.5195 - acc: 0.7823 - val_loss: 0.3222 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00026: saving model to chkp/weights.26-0.32.hdf5\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 174s 6s/step - loss: 0.5998 - acc: 0.8185 - val_loss: 0.7247 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00027: saving model to chkp/weights.27-0.72.hdf5\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 174s 6s/step - loss: 0.5885 - acc: 0.7581 - val_loss: 0.9629 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00028: saving model to chkp/weights.28-0.96.hdf5\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 166s 5s/step - loss: 0.5804 - acc: 0.7702 - val_loss: 0.1473 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00029: saving model to chkp/weights.29-0.15.hdf5\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 161s 5s/step - loss: 0.5187 - acc: 0.7823 - val_loss: 0.1185 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00030: saving model to chkp/weights.30-0.12.hdf5\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 161s 5s/step - loss: 0.5608 - acc: 0.7984 - val_loss: 0.5281 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00031: saving model to chkp/weights.31-0.53.hdf5\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 173s 6s/step - loss: 0.5457 - acc: 0.7823 - val_loss: 0.4557 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00032: saving model to chkp/weights.32-0.46.hdf5\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 172s 6s/step - loss: 0.5325 - acc: 0.7823 - val_loss: 0.6744 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00033: saving model to chkp/weights.33-0.67.hdf5\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 169s 5s/step - loss: 0.5384 - acc: 0.7742 - val_loss: 0.3808 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00034: saving model to chkp/weights.34-0.38.hdf5\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 170s 5s/step - loss: 0.5858 - acc: 0.7742 - val_loss: 0.0949 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00035: saving model to chkp/weights.35-0.09.hdf5\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 158s 5s/step - loss: 0.4421 - acc: 0.8226 - val_loss: 0.2842 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00036: saving model to chkp/weights.36-0.28.hdf5\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 162s 5s/step - loss: 0.5516 - acc: 0.7863 - val_loss: 0.2903 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00037: saving model to chkp/weights.37-0.29.hdf5\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 158s 5s/step - loss: 0.5311 - acc: 0.7903 - val_loss: 0.4703 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00038: saving model to chkp/weights.38-0.47.hdf5\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 151s 5s/step - loss: 0.4409 - acc: 0.8347 - val_loss: 0.1355 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00039: saving model to chkp/weights.39-0.14.hdf5\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 151s 5s/step - loss: 0.4266 - acc: 0.8145 - val_loss: 0.6620 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00040: saving model to chkp/weights.40-0.66.hdf5\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 148s 5s/step - loss: 0.5010 - acc: 0.7984 - val_loss: 0.3659 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00041: saving model to chkp/weights.41-0.37.hdf5\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 149s 5s/step - loss: 0.4766 - acc: 0.7944 - val_loss: 0.5948 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00042: saving model to chkp/weights.42-0.59.hdf5\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 146s 5s/step - loss: 0.4321 - acc: 0.8387 - val_loss: 0.4421 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00043: saving model to chkp/weights.43-0.44.hdf5\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 146s 5s/step - loss: 0.4258 - acc: 0.8508 - val_loss: 0.3309 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00044: saving model to chkp/weights.44-0.33.hdf5\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 145s 5s/step - loss: 0.4322 - acc: 0.8024 - val_loss: 0.1961 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00045: saving model to chkp/weights.45-0.20.hdf5\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 147s 5s/step - loss: 0.5133 - acc: 0.8145 - val_loss: 0.0948 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00046: saving model to chkp/weights.46-0.09.hdf5\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 146s 5s/step - loss: 0.4495 - acc: 0.8024 - val_loss: 0.3988 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00047: saving model to chkp/weights.47-0.40.hdf5\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 146s 5s/step - loss: 0.4529 - acc: 0.8548 - val_loss: 0.4070 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00048: saving model to chkp/weights.48-0.41.hdf5\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 146s 5s/step - loss: 0.3844 - acc: 0.8629 - val_loss: 0.4496 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00049: saving model to chkp/weights.49-0.45.hdf5\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 144s 5s/step - loss: 0.4262 - acc: 0.8306 - val_loss: 0.1001 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00050: saving model to chkp/weights.50-0.10.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1705e83cd48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss');\n",
    "plt.plot(history.history['val_loss'], label='val_loss');\n",
    "plt.xlabel('epoch');\n",
    "plt.title('Loss and Validation Loss per Epoch')\n",
    "plt.legend();\n",
    "plt.savefig('loss_val_loss_convnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy');\n",
    "plt.plot(history.history['val_acc'], label='val_accuracy');\n",
    "plt.xlabel('epoch');\n",
    "plt.title('Accuracy and Validation Accuracy per Epoch')\n",
    "plt.legend();\n",
    "plt.savefig('acc_val_acc_convnet.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
