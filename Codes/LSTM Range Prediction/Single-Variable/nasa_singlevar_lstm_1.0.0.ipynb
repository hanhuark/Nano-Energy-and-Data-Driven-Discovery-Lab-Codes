{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from numpy import array\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # Finding the end of the pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        \n",
    "        # Checking if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "            \n",
    "        # Gather input and output parts of pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix: out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def load_col(txtfile, col, process):\n",
    "    dataset = pandas.read_csv(txtfile, sep='\\t',\n",
    "                               header=None,usecols=[col])\n",
    "    if process==True:\n",
    "        #dataset = dataset.values[2:]\n",
    "        dataset = dataset.astype('float32')\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        return dataset, scaler\n",
    "    elif process==False:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = \"temperature.txt\"\n",
    "C = 0\n",
    "E = 20\n",
    "I = 100\n",
    "O = 100\n",
    "B = 5\n",
    "M = \"nasa_temperature_100_100.h5\"\n",
    "T = \"nasa_temperature_100_100_outfile.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35136318]\n",
      " [0.3301134 ]\n",
      " [0.30907965]\n",
      " [0.28782988]\n",
      " [0.27559614]\n",
      " [0.26336145]\n",
      " [0.25112677]\n",
      " [0.25262928]\n",
      " [0.25391722]\n",
      " [0.25520515]]\n"
     ]
    }
   ],
   "source": [
    "# Load data from text file with selected columns, scaled to (0,1)\n",
    "data_array, data_scaler = load_col(F, C, True)\n",
    "print(data_array[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "done!\n",
      "preparing model...\n",
      "done!\n",
      "training model...\n",
      "Epoch 1/20\n",
      "3905/3905 [==============================] - 45s 11ms/step - loss: 159.2701\n",
      "Epoch 2/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0174 0s - loss\n",
      "Epoch 3/20\n",
      "3905/3905 [==============================] - 44s 11ms/step - loss: 0.0171\n",
      "Epoch 4/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0170- ETA: 0s - loss: 0.01\n",
      "Epoch 5/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0171\n",
      "Epoch 6/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0169 0s - \n",
      "Epoch 7/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0168\n",
      "Epoch 8/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0167\n",
      "Epoch 9/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0164\n",
      "Epoch 10/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0160\n",
      "Epoch 11/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0159\n",
      "Epoch 12/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0157\n",
      "Epoch 13/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0156\n",
      "Epoch 14/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0143\n",
      "Epoch 15/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0128\n",
      "Epoch 16/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0125\n",
      "Epoch 17/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0115\n",
      "Epoch 18/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0110\n",
      "Epoch 19/20\n",
      "3905/3905 [==============================] - 46s 12ms/step - loss: 0.0109\n",
      "Epoch 20/20\n",
      "3905/3905 [==============================] - 45s 12ms/step - loss: 0.0105\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "n_steps_in = I\n",
    "n_steps_out = O\n",
    "dataset = data_array\n",
    "n_features = 1\n",
    "\n",
    "print(\"preparing data...\")\n",
    "X_dataset, y_dataset = split_sequence(data_array, n_steps_in, n_steps_out)\n",
    "y_dataset = y_dataset.reshape((y_dataset.shape[0], y_dataset.shape[1]))\n",
    "print(\"done!\")\n",
    "    \n",
    "print(\"preparing model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=False))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "print(\"done!\")\n",
    "\n",
    "print(\"training model...\")\n",
    "history = model.fit(X_dataset, y_dataset, epochs=E, batch_size=B, verbose=1)\n",
    "model_name = M\n",
    "model.save(model_name)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed txt file\n"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "outputfilename = T\n",
    "\n",
    "output_file = open(outputfilename, \"w\")\n",
    "\n",
    "output_file.write(\"loss\\n\")\n",
    "for i in range(len(loss)):\n",
    "    output_file.write(str(loss[i]))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "print(\"Closed txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = \"temperature.txt\"\n",
    "C = 0\n",
    "E = 20\n",
    "I = 200\n",
    "O = 200\n",
    "B = 128\n",
    "M = \"nasa_temperature_200_200.h5\"\n",
    "T = \"nasa_temperature_200_200_outfile.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35136318]\n",
      " [0.3301134 ]\n",
      " [0.30907965]\n",
      " [0.28782988]\n",
      " [0.27559614]\n",
      " [0.26336145]\n",
      " [0.25112677]\n",
      " [0.25262928]\n",
      " [0.25391722]\n",
      " [0.25520515]]\n"
     ]
    }
   ],
   "source": [
    "# Load data from text file with selected columns, scaled to (0,1)\n",
    "data_array, data_scaler = load_col(F, C, True)\n",
    "print(data_array[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "done!\n",
      "preparing model...\n",
      "done!\n",
      "training model...\n",
      "Epoch 1/20\n",
      "3705/3705 [==============================] - 55s 15ms/step - loss: nan\n",
      "Epoch 2/20\n",
      "3705/3705 [==============================] - 57s 15ms/step - loss: nan\n",
      "Epoch 3/20\n",
      "3705/3705 [==============================] - 59s 16ms/step - loss: nan\n",
      "Epoch 4/20\n",
      "3705/3705 [==============================] - 59s 16ms/step - loss: nan\n",
      "Epoch 5/20\n",
      "3705/3705 [==============================] - 60s 16ms/step - loss: nan\n",
      "Epoch 6/20\n",
      "3705/3705 [==============================] - 59s 16ms/step - loss: nan\n",
      "Epoch 7/20\n",
      "3705/3705 [==============================] - 60s 16ms/step - loss: nan\n",
      "Epoch 8/20\n",
      "3705/3705 [==============================] - 61s 16ms/step - loss: nan\n",
      "Epoch 9/20\n",
      "3705/3705 [==============================] - 61s 16ms/step - loss: nan\n",
      "Epoch 10/20\n",
      "3705/3705 [==============================] - 61s 17ms/step - loss: nan\n",
      "Epoch 11/20\n",
      "3705/3705 [==============================] - 62s 17ms/step - loss: nan\n",
      "Epoch 12/20\n",
      "3705/3705 [==============================] - 62s 17ms/step - loss: nan\n",
      "Epoch 13/20\n",
      "3705/3705 [==============================] - 62s 17ms/step - loss: nan\n",
      "Epoch 14/20\n",
      "3705/3705 [==============================] - 61s 17ms/step - loss: nan\n",
      "Epoch 15/20\n",
      "3705/3705 [==============================] - 62s 17ms/step - loss: nan\n",
      "Epoch 16/20\n",
      "3705/3705 [==============================] - 63s 17ms/step - loss: nan\n",
      "Epoch 17/20\n",
      "3705/3705 [==============================] - 64s 17ms/step - loss: nan\n",
      "Epoch 18/20\n",
      "3705/3705 [==============================] - 63s 17ms/step - loss: nan\n",
      "Epoch 19/20\n",
      "3705/3705 [==============================] - 64s 17ms/step - loss: nan\n",
      "Epoch 20/20\n",
      "3705/3705 [==============================] - 65s 18ms/step - loss: nan\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "n_steps_in = I\n",
    "n_steps_out = O\n",
    "dataset = data_array\n",
    "n_features = 1\n",
    "\n",
    "print(\"preparing data...\")\n",
    "X_dataset, y_dataset = split_sequence(data_array, n_steps_in, n_steps_out)\n",
    "y_dataset = y_dataset.reshape((y_dataset.shape[0], y_dataset.shape[1]))\n",
    "print(\"done!\")\n",
    "    \n",
    "print(\"preparing model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=False))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "print(\"done!\")\n",
    "\n",
    "print(\"training model...\")\n",
    "history = model.fit(X_dataset, y_dataset, epochs=E, batch_size=B, verbose=1)\n",
    "model_name = M\n",
    "model.save(model_name)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "outputfilename = T\n",
    "\n",
    "output_file = open(outputfilename, \"w\")\n",
    "\n",
    "output_file.write(\"loss\\n\")\n",
    "for i in range(len(loss)):\n",
    "    output_file.write(str(loss[i]))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "print(\"Closed txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
